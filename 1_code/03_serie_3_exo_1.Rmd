---
title: "Solution Exercice #1, Série 3"
author: "Francis Duval"
date: "11 février 2020"
output: html_document
---

<style>
    body .main-container {
        max-width: 1200px;
    }
</style>

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = T, tidy = T)
```

Pour les énoncés des exercices, cliquer sur ce lien: <https://nbviewer.jupyter.org/github/nmeraihi/ACT6100/blob/master/exercices_3.ipynb>

Activer les librairies utiles.

```{r message = FALSE}
library(here)
library(tidyverse)
library(magrittr)
library(glue)
```


Lire la base de données `swmotorcycle.rda`.

```{r}
load(here("0_data", "swmotorcycle.rda"))
```

Pour voir rapidement à quoi ressemble la base de données, on peut utiliser la fonction `glimpse`.

```{r}
glimpse(swmotorcycle)
```

## Partie 1

Premièrement, on va regarder combien de valeurs manquantes ont chacune des variables `OwnerAge`, `Exposure` et `ClaimNb` (parce que pour ajuster un GLM, aucune valeur ne doit être manquante).

```{r}
swmotorcycle %>% select(ClaimNb, Exposure, OwnerAge) %>% map(~ sum(is.na(.)))
```

Parfait, aucune valeur n'est manquante. Cependant, on peut remarquer que la variable `Exposure` prend quelquefois la valeur zéro.

```{r}
sum(swmotorcycle$Exposure == 0)
```

On voit que pour `r sum(swmotorcycle$Exposure == 0)` lignes de la base de données, l'exposition est nulle. Ça ne fonctionnera pas dans un GLM. On va donc supprimer ces lignes (avec la fonction `dplyr::filter`), et en même temps on va se créer une nouvelle base de données appelée `data_glm`. 

```{r}
data_glm <- swmotorcycle %>% 
  filter(Exposure != 0)
```

Si on regarde les valeurs que la variable `OwnerAge` peut prendre, on voit que plusieurs assurés ont moins de 16 ans.

```{r}
table(swmotorcycle$OwnerAge)
```

Par exemple, 1 assuré a 0 an, 1 assuré a 4 ans, 2 assurés ont 5 ans, etc. On va supposer qu'un assuré ne peut avoir que 16 ans ou plus, donc on va supprimer les contrats avec des assurés de 15 ans ou moins (avec la fonction `dplyr::filter`).

```{r}
data_glm %<>% filter(OwnerAge > 15) 
```

On va aussi seulement garder les variables utiles pour la modélisation (avec la fonction `dplyr::select`).

```{r}
data_glm %<>% 
  select(ClaimNb, Exposure, OwnerAge)
```

On ajuste ensuite un GLM Poisson avec fonction de lien logarithmique et avec la variable `Exposure` en offset.

```{r}
glm_pois_fit <- glm(ClaimNb ~ OwnerAge + offset(log(Exposure)),family = poisson(link = "log"), data = data_glm)
summary(glm_pois_fit)
```

Les coefficients sont

```{r}
coef(glm_pois_fit)
```

## Partie 2

Pour déterminer la valeur optimale de K sans validation croisée, on pourrait par exemple essayer toutes les valeurs possibles de K, calculer l'AIC pour toutes ces valeurs et garder la valeur de K qui minimise l'AIC. Observons premièrement quelles valeurs la variable `OwnerAge` peut prendre, ainsi que le nombre de valeurs possibles.

```{r}
unique(data_glm$OwnerAge)
length(unique(data_glm$OwnerAge))
```

On voit que la variable `OwnerAge` peut prendre `r length(unique(data_glm$OwnerAge))` valeurs différentes, soient `r min(data_glm$OwnerAge)`, ..., `r max(data_glm$OwnerAge)`. Il y a donc `r length(unique(data_glm$OwnerAge)) - 1` manières de séparer la variable `OwnerAge` en 2 catégories (K = `r min(data_glm$OwnerAge)`, ..., `r max(data_glm$OwnerAge) -1`). Cependant, puisque la valeur `OwnerAge` ne prend pas souvent des valeurs en haut de 75, on n'essayera pas ces valeurs. On va donc se créer 59 bases de données (avec chacune une valeur de K différente), ajuster un GLM Poisson sur chacune, calculer l'AIC pour chaque modèle et finalement, choisir la valeur de K qui mène au plus petit AIC.

On commence par créer les `r length(unique(data_glm$OwnerAge)) - 1` bases de données, qu'on va stocker dans la liste `data_glm_ls`.

```{r}
# Fonction qui renvoie la base de données data_glm mais avec une variable age catégorielle à 2 classes (spécifier valeur k)
creer_variable_age_2_classes <- function(k) {
  data_glm %>% 
    mutate(
      OwnerAge_2_classes = factor(if_else(OwnerAge <= k, glue("{k} ans ou moins"), glue("Plus de {k} ans")))
    )  
}

# Obtenir toutes les valeurs de k possibles
(valeurs_k <- head(unique(data_glm$OwnerAge), -14))

# Obtenir une liste avec les 72 bases de données
data_glm_ls <- map(valeurs_k, creer_variable_age_2_classes)
```

Observons par exemple la structure du 10eme élément de cette liste.

```{r}
glimpse(data_glm_ls[[10]])
```

Ensuite on ajuste un GLM Poisson sur chacune des bases de données de cette liste, qu'on stocke aussi dans une liste.

```{r}
glm_pois_fit_ls <- map(
  data_glm_ls, 
  ~ glm(ClaimNb ~ OwnerAge_2_classes + offset(log(Exposure)), family = poisson(link = "log"), data = .x)
)
```

Ensuite on calcule l'AIC pour chacun des modèles

```{r}
(AIC_vec <- map_dbl(glm_pois_fit_ls, AIC))
```

```{r}
(k_opt_AIC <- valeurs_k[which.min(AIC_vec)])
```

La valeur optimale est K = `r k_opt_AIC` selon l'AIC. Voici le code pour obtenir la fréquence espérée de chacune des 2 classes de risque (30 ans ou moins et plus de 30 ans):

```{r}
new_data <- tibble(
  Exposure = c(1, 1),
  OwnerAge_2_classes = factor(c("30 ans ou moins", "Plus de 30 ans"))
)

new_data %>%
  mutate(frequence_esperee = round(predict(glm_pois_fit_ls[[which.min(AIC_vec)]], newdata = ., type = "response"), 4))
```

Maintenant, on va déterminer la valeur optimale de K, mais avec la validation croisée. On va premièrement créer une fonction qui prend en entrée une base de données et qui retourne l'erreur quadratique moyenne de validation croisée avec 12 "folds".

```{r}
# Définir une fonction qui prend en entrée un nombre n et renvoie 12 "folds" de taille égale
create_folds <- function(n, theseed = 2020) {
  set.seed(theseed)
  seq(1, n) %>% 
    cut(breaks = 12, labels = F) %>% 
    sample() %>% 
    factor()
}

# Définir une fonction qui prend en entrée une base de données et renvoie l'erreur quadratique moyenne de validation croisée
cv_12_folds_mse_glm_poisson <- function(data) {
  data %<>% mutate(fold = create_folds(nrow(.)))
  responses_ls <- data %>% group_split(fold) %>% map(~ pull(., ClaimNb))
  models_ls <- map(
    1:12, 
    ~ glm(ClaimNb ~ OwnerAge_2_classes + offset(log(Exposure)), family = poisson(link = "log"), data = filter(data, fold != .))
  )
  predictions_ls <- map(1:12, ~ predict(models_ls[[.]], newdata = filter(data, fold == .), type = "response"))
  res <- map2(responses_ls, predictions_ls, ~ mean((.x - .y) ^ 2)) %>% flatten_dbl() %>% mean()
  return(res)
}
```

Ensuite on calcule l'erreur quadratique moyenne de validation croisée pour chacune des bases de données dans la liste `data_glm_ls`.

```{r}
(eqm_vec <- map_dbl(data_glm_ls, cv_12_folds_mse_glm_poisson))
```

La valeur de K optimale s'obtient avec le code suivant:

```{r}
(k_opt_eqm <- valeurs_k[which.min(eqm_vec)])
```

On rajuste un GLM Poisson avec la valeur optimale de K sur la base de données complète et on calcule les fréquences espérées:

```{r}
glm_pois_fit_opt_k_eqm <- glm(
  ClaimNb ~ OwnerAge_2_classes + offset(log(Exposure)), 
  family = poisson(link = "log"), 
  data = data_glm_ls[[which.min(eqm_vec)]]
)

new_data_eqm <- tibble(
  Exposure = c(1, 1),
  OwnerAge_2_classes = factor(c("30 ans ou moins", "Plus de 30 ans"))
)

new_data_eqm %>%
  mutate(frequence_esperee = round(predict(glm_pois_fit_opt_k_eqm, newdata = ., type = "response"), 4))
```
